{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXXyXxENg4wV"
      },
      "source": [
        "#Preparação"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WVulohkhRuN3"
      },
      "outputs": [],
      "source": [
        "#Muda o lugar de referencia e agora pode importar os arquivos .py dessa pasta no caminho\n",
        "import sys\n",
        "sys.path.insert(0,'/home/monitora/Documents/Motion and Region A A L F D  T I')\n",
        "sys.path.insert(0,'/home/monitora/Documents/Motion and Region A A L F D  T I/mrfd')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SlID-M0oOEIN",
        "outputId": "195f4602-a766-4623-b7f0-9160535f55b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['/home/midiacom/Documentos/Motion and Region A A L F D  T I/mrfd', '/home/midiacom/Documentos/Motion and Region A A L F D  T I', '/home/midiacom/Documentos/Motion and Region A A L F D  T I/mrfd', '/home/midiacom/anaconda3/envs/vin_old_tf/lib/python37.zip', '/home/midiacom/anaconda3/envs/vin_old_tf/lib/python3.7', '/home/midiacom/anaconda3/envs/vin_old_tf/lib/python3.7/lib-dynload', '', '/home/midiacom/anaconda3/envs/vin_old_tf/lib/python3.7/site-packages', '/home/midiacom/anaconda3/envs/vin_old_tf/lib/python3.7/site-packages/IPython/extensions', '/home/midiacom/.ipython']\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "print(sys.path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CKcwtxQak4zK",
        "outputId": "6d35707c-1c13-4bdd-b9ad-2417979de6d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python 3.7.6\r\n"
          ]
        }
      ],
      "source": [
        "!python --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZQnYZk67lXHL"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "cv2.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UnUAElwHdDPl"
      },
      "outputs": [],
      "source": [
        "import tensorflow\n",
        "tensorflow.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ldjlqt4dJFb"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "keras.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "keVkAhUoOEIc"
      },
      "source": [
        "## Fall"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "atCGfSodOEId"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import glob\n",
        "import shutil\n",
        "import datetime\n",
        "\n",
        "TEXT_COLOR = (0, 255, 0)\n",
        "TRACKER_COLOR = (255, 255, 255)\n",
        "FONT = cv2.FONT_HERSHEY_SIMPLEX\n",
        "BGS_TYPES = [\"GMG\", \"MOG\", \"MOG2\", \"KNN\", \"CNT\"]\n",
        "BGS_TYPE = BGS_TYPES[4]\n",
        "minArea = 500\n",
        "maxArea= 15000\n",
        "\n",
        "def getKernel(KERNEL_TYPE):\n",
        "    if KERNEL_TYPE == \"dilation\":\n",
        "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
        "    if KERNEL_TYPE == \"opening\":\n",
        "        kernel = np.ones((3, 3), np.uint8)\n",
        "    if KERNEL_TYPE == \"closing\":\n",
        "        kernel = np.ones((3, 3), np.uint8)\n",
        "\n",
        "    return kernel\n",
        "\n",
        "def getFilter(img, filter):\n",
        "    if filter == 'closing':\n",
        "        return cv2.morphologyEx(img, cv2.MORPH_CLOSE, getKernel(\"closing\"), iterations=2)\n",
        "\n",
        "    if filter == 'opening':\n",
        "        return cv2.morphologyEx(img, cv2.MORPH_OPEN, getKernel(\"opening\"), iterations=2)\n",
        "\n",
        "    if filter == 'dilation':\n",
        "        return cv2.dilate(img, getKernel(\"dilation\"), iterations=2)\n",
        "\n",
        "    if filter == 'combine':\n",
        "        closing = cv2.morphologyEx(img, cv2.MORPH_CLOSE, getKernel(\"closing\"), iterations=2)\n",
        "        opening = cv2.morphologyEx(closing, cv2.MORPH_OPEN, getKernel(\"opening\"), iterations=2)\n",
        "        dilation = cv2.dilate(opening, getKernel(\"dilation\"), iterations=2)\n",
        "\n",
        "        return dilation\n",
        "\n",
        "def getBGSubtractor(BGS_TYPE):\n",
        "    if BGS_TYPE == \"GMG\":\n",
        "        return cv2.bgsegm.createBackgroundSubtractorGMG()\n",
        "    if BGS_TYPE == \"MOG\":\n",
        "        return cv2.bgsegm.createBackgroundSubtractorMOG()\n",
        "    if BGS_TYPE == \"MOG2\":\n",
        "        return cv2.createBackgroundSubtractorMOG2()\n",
        "    if BGS_TYPE == \"KNN\":\n",
        "        return cv2.createBackgroundSubtractorKNN()\n",
        "    if BGS_TYPE == \"CNT\":\n",
        "        return cv2.bgsegm.createBackgroundSubtractorCNT()\n",
        "    print(\"Detector invÃ¡lido\")\n",
        "    sys.exit(1)\n",
        "\n",
        "def FMT(VIDEO_SOURCE,tipo=\"RGB\"):\n",
        "    cap = cv2.VideoCapture(VIDEO_SOURCE)\n",
        "    print('contagem de todos os frames do video')\n",
        "    print(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "    #print('gera 25 numeros aleatorios')\n",
        "    #print(np.random.uniform(size=25))\n",
        "\n",
        "    print('seleciona 25 frames aleatorios do video')\n",
        "    framesIds = cap.get(cv2.CAP_PROP_FRAME_COUNT) * np.random.uniform(size=25)\n",
        "    #print(framesIds)\n",
        "    \n",
        "    #armazena os 25 frames em um array\n",
        "    frames = []\n",
        "    for fid in framesIds:\n",
        "        cap.set(cv2.CAP_PROP_POS_FRAMES, fid)\n",
        "        hasFrame, frame = cap.read()\n",
        "        frames.append(frame)\n",
        "\n",
        "    print('numero de frames')\n",
        "    print(np.asarray(frames).shape)\n",
        "    #print('exemplos')\n",
        "    #print(frames[0])\n",
        "    #print(frames[1])\n",
        "    \n",
        "    #calculo da mediana de cada uma das imagens considerando todos os pixels (por causa do axis=0, vai por linha)\n",
        "    medianFrame = np.median(frames, axis=0).astype(dtype=np.uint8)\n",
        "    #print('imprime o primeiro frame de exemplo')\n",
        "    #print(frame[0])\n",
        "    #print('imprime a imagem de plano de fundo em forma de matriz')\n",
        "    #print(medianFrame)\n",
        "    #print('imprime a imagem de plano de fundo')\n",
        "    #cv2_imshow(medianFrame)\n",
        "\n",
        "    #cv2.imwrite('model_median_frame.jpg', medianFrame)\n",
        "\n",
        "    #print('converte para cinza')\n",
        "    cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
        "    grayMedianFrame = cv2.cvtColor(medianFrame, cv2.COLOR_BGR2GRAY)\n",
        "    #cv2_imshow(grayMedianFrame)\n",
        "\n",
        "    #RGB\n",
        "    if tipo==\"RGB\":\n",
        "        grayMedianFrame = grayMedianFrame[:,300:1750]\n",
        "    #IR\n",
        "    if tipo==\"IR\":\n",
        "        grayMedianFrame = grayMedianFrame[10:410,50:450]\n",
        "    \n",
        "    grayMedianFrame = cv2.resize(grayMedianFrame, (640, 480))\n",
        "    \n",
        "    cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
        "    return grayMedianFrame\n",
        "    \n",
        "    \n",
        "def main(contador_frame_real,contador_frame,VIDEO_SOURCE,video_path_temp,tipo=\"RGB\",filtro=\"0\",video_out=True):\n",
        "    #FMT\n",
        "    #grayMedianFrame=FMT(VIDEO_SOURCE,tipo)\n",
        "    \n",
        "    cap = cv2.VideoCapture(VIDEO_SOURCE)\n",
        "    bg_subtractor = getBGSubtractor(BGS_TYPE)\n",
        "    \n",
        "    if video_out:\n",
        "        VIDEO_OUT = os.path.join(video_path_temp,\"video.avi\")\n",
        "        fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
        "        writer = cv2.VideoWriter(VIDEO_OUT, fourcc, 25, (640, 480), False)\n",
        "    \n",
        "    timestamps=[]\n",
        "    # count the number of frames\n",
        "    #frames = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
        "    #fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    #print(frames / fps)\n",
        "    #seconds = round(frames / fps)\n",
        "    #print(f\"duration in seconds: {seconds}\")\n",
        "    \n",
        "    #video_time = datetime.timedelta(seconds=seconds)\n",
        "    #print(f\"video time: {video_time}\")\n",
        "        \n",
        "    while (cap.isOpened):\n",
        "\n",
        "        ok, frame = cap.read()\n",
        "        if not ok:\n",
        "            print(\"Erro\")\n",
        "            break\n",
        "        \n",
        "        #em milisegundos\n",
        "        #timestamps.append(cap.get(cv2.CAP_PROP_POS_MSEC))\n",
        "        #em segundos\n",
        "        #timestamps.append(cap.get(cv2.CAP_PROP_POS_MSEC)*10**-3)\n",
        "        \n",
        "        contador_frame_real+=1\n",
        "        i=contador_frame_real\n",
        "        #contador_frame+=1\n",
        "        numero_de_copias1=2 #6\n",
        "        numero_de_copias2=2  #3\n",
        "        \n",
        "        #IR\n",
        "        if tipo==\"IR\":\n",
        "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "            frame = frame[10:410,50:450]\n",
        "        #RGB\n",
        "        if tipo==\"RGB\":\n",
        "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "            frame = frame[:,300:1750]\n",
        "        \n",
        "        #frame = cv2.resize(frame, (0, 0), fx=0.50, fy=0.50)\n",
        "        frame = cv2.resize(frame, (640, 480))\n",
        "        #cv2.imshow(\"frame original\",frame)\n",
        "\n",
        "        \n",
        "        #result = cv2.bitwise_and(frame, frame, mask=bg_mask)\n",
        "        #cv2.imshow('Frame', frame)\n",
        "        #cv2.imshow('Mask', result)\n",
        "        #frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "        #cv2_imshow(frame)\n",
        "\n",
        "\n",
        "\n",
        "        ########## FMT\n",
        "\n",
        "        #faz a diferença do frame com o fundo\n",
        "        #bg_mask = cv2.absdiff(frame, grayMedianFrame)\n",
        "        #cv2.imshow(\"absdiff\",bg_mask)\n",
        "        #redimenciona\n",
        "        #dframe = cv2.resize(dframe, (0, 0), fx=0.40, fy=0.40)\n",
        "\n",
        "        #threashold para ajustar e tirar o ruido \n",
        "        #th, dframe = cv2.threshold(dframe, 70, 255, cv2.THRESH_BINARY)\n",
        "        ##th, dframe = cv2.threshold(dframe, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
        "        #print(th)\n",
        "        #######\n",
        "\n",
        "        #####Filtro\n",
        "        #bg_mask = bg_subtractor.apply(frame)\n",
        "        #cv2.imshow(\"1mg_mask\",bg_mask)\n",
        "        #th, bg_mask = cv2.threshold(bg_mask, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
        "        #bg_mask = getFilter(bg_mask, 'combine')\n",
        "        #bg_mask = cv2.medianBlur(bg_mask, 5)\n",
        "        ######\n",
        "\n",
        "        filtro = str(filtro)\n",
        "        if filtro==\"0\":\n",
        "            pass\n",
        "        else:\n",
        "            for letra in filtro:\n",
        "                if letra ==\"T\":\n",
        "                    #th, bg_mask = cv2.threshold(bg_mask, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
        "                    #cv2.imshow(\"t\",bg_mask)\n",
        "                    th, frame = cv2.threshold(frame, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
        "                if letra==\"O\":\n",
        "                    #bg_mask = getFilter(bg_mask, 'opening')\n",
        "                    #cv2.imshow(\"o\",bg_mask)\n",
        "                    frame = getFilter(frame, 'opening')\n",
        "                if letra==\"C\":\n",
        "                    #bg_mask = getFilter(bg_mask, 'closing')\n",
        "                    #cv2.imshow(\"c\",bg_mask)\n",
        "                    frame = getFilter(frame, 'closing')\n",
        "                if letra==\"D\":\n",
        "                    #bg_mask = getFilter(bg_mask, 'dilation')\n",
        "                    #cv2.imshow(\"d\",bg_mask)\n",
        "                    frame = getFilter(frame, 'dilation')\n",
        "                if letra==\"B\":\n",
        "                    #bg_mask = cv2.medianBlur(bg_mask, 5)\n",
        "                    #cv2.imshow(\"b\",bg_mask)\n",
        "                    frame = cv2.medianBlur(frame, 5)\n",
        "\n",
        "        ##### Final\n",
        "        bg_mask = bg_subtractor.apply(frame)\n",
        "        frame = cv2.bitwise_and(frame, frame, mask=bg_mask)\n",
        "        #cv2.imshow(\"bitwise_and\",frame)\n",
        "        #FMT1\n",
        "        #frame=bg_mask\n",
        "        #######\n",
        "\n",
        "        #Depois fazer outro sistema fazer essa parte final, mas usando o dframe (so a mascara)\n",
        "        \n",
        "        #Faz o video\n",
        "\n",
        "        \n",
        "\n",
        "        try:\n",
        "            writer.write(frame)\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "#        i = str(i).zfill(4)\n",
        "#        #salva o frame no meu google drive\n",
        "#        cv2.imwrite('/content/gdrive/MyDrive/Colab Notebooks/Allan Fall/Fall37/FALL_37-'+ i +'.jpg', frame)\n",
        "#        i = int(i)\n",
        "\n",
        "        if contador_frame_real < 12:\n",
        "          #i = str(i).zfill(4)\n",
        "              for contador_de_copias in range(0, numero_de_copias1):\n",
        "                    contador_frame = contador_frame + 1\n",
        "                    contador_frame = str(contador_frame).zfill(4)\n",
        "                    ###print(contador_frame)\n",
        "                    #salva o frame no meu google drive\n",
        "                    cv2.imwrite(video_path_temp +'/FALL_37-'+ contador_frame +'.jpg', frame)\n",
        "                    #cv2.imwrite('/content/FALL_37-'+ i +'.jpg', frame)\n",
        "                    contador_frame = int(contador_frame)\n",
        "                    timestamps.append(cap.get(cv2.CAP_PROP_POS_MSEC)*10**-3)\n",
        "        elif (contador_frame_real >=12 and contador_frame_real<50):\n",
        "              for contador_de_copias in range(0, numero_de_copias2): \n",
        "                    contador_frame = contador_frame + 1\n",
        "                    contador_frame = str(contador_frame).zfill(4)\n",
        "                    ###print(contador_frame)\n",
        "                    #salva o frame no meu google drive\n",
        "                    cv2.imwrite(video_path_temp+'/FALL_37-'+ contador_frame +'.jpg', frame)\n",
        "                    #cv2.imwrite('/content/FALL_37-'+ i +'.jpg', frame)\n",
        "                    contador_frame = int(contador_frame)\n",
        "                    timestamps.append(cap.get(cv2.CAP_PROP_POS_MSEC)*10**-3)\n",
        "        elif contador_frame_real >50:\n",
        "              for contador_de_copias in range(0, numero_de_copias1):\n",
        "                    contador_frame = contador_frame + 1\n",
        "                    contador_frame = str(contador_frame).zfill(4)\n",
        "                    ###print(contador_frame)\n",
        "                    #salva o frame no meu google drive\n",
        "                    cv2.imwrite(video_path_temp+'/FALL_37-'+ contador_frame +'.jpg', frame)\n",
        "                    #cv2.imwrite('/content/FALL_37-'+ i +'.jpg', frame)\n",
        "                    contador_frame = int(contador_frame)\n",
        "                    timestamps.append(cap.get(cv2.CAP_PROP_POS_MSEC)*10**-3)\n",
        "        \n",
        "\n",
        "        if (contador_frame_real%2==0):\n",
        "            frame_show = cv2.resize(frame, (320, 240))\n",
        "          #cv2_imshow(frame_show)\n",
        "\n",
        "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
        "            break\n",
        "\n",
        "    try:\n",
        "        writer.release()\n",
        "    except:\n",
        "        pass\n",
        "    cap.release()\n",
        "    return timestamps\n",
        "\n",
        "\n",
        "def criando_novo_teste(tipo=\"RGB\",filtro=\"0\"):\n",
        "    pasta_pra_rodar = \"/home/monitora/Documents/Motion and Region A A L F D  T I/dataset/Thermal/frame/Fall\"\n",
        "    \n",
        "    if tipo == \"RGB\":\n",
        "        source_folder = \"/home/monitora/Documents/Motion and Region A A L F D  T I/Fall/RGB\"\n",
        "    if tipo == \"IR\":\n",
        "        source_folder = \"/home/monitora/Documents/Motion and Region A A L F D  T I/Fall\"\n",
        "    \n",
        "    dst_folder_rodados =  os.path.join( source_folder,'Rodados')\n",
        "    dst_folder_resultados = os.path.join( source_folder,'Resultados')\n",
        "    dst_folder_fail = os.path.join( source_folder,'Fail')\n",
        "    Resultados_dos_CVSC=os.path.join(source_folder,\"Resultados_dos_CVSC\")\n",
        "    #print(os.listdir(source_folder))\n",
        "    \n",
        "    rodar=True\n",
        "    for pasta in os.listdir(Resultados_dos_CVSC):\n",
        "        if pasta==\"CVSC CNT2 \"+str(filtro):\n",
        "            rodar=False\n",
        "    if rodar==True:     \n",
        "        for file in os.listdir(source_folder):\n",
        "            if os.path.isfile(os.path.join(source_folder,file)):\n",
        "                video_da_vez = file\n",
        "                VIDEO_SOURCE = os.path.join(source_folder,video_da_vez)\n",
        "                video_path_temp=os.path.join(source_folder,\"Fall37\")\n",
        "\n",
        "                try:\n",
        "                    if os.path.exists(video_path_temp):\n",
        "                        shutil.rmtree(video_path_temp)\n",
        "                        os.makedirs(video_path_temp)\n",
        "                    if not os.path.exists(video_path_temp):\n",
        "                        os.makedirs(video_path_temp)\n",
        "                except OSError:\n",
        "                    print ('Error: Creating directory of data')\n",
        "\n",
        "\n",
        "                timestamps=main(0,0,VIDEO_SOURCE,video_path_temp,tipo,filtro)\n",
        "\n",
        "                #pasta_pra_rodar = \"/home/monitora/Documents/Motion and Region A A L F D  T I/dataset/Thermal/frame/Fall\" \n",
        "                if os.path.exists(os.path.join(pasta_pra_rodar,\"Fall37\")):\n",
        "                    shutil.rmtree(os.path.join(pasta_pra_rodar,\"Fall37\"))\n",
        "                    shutil.move(video_path_temp, pasta_pra_rodar)\n",
        "\n",
        "                if not os.path.exists(os.path.join(pasta_pra_rodar,\"Fall37\")):\n",
        "                    shutil.move(video_path_temp, pasta_pra_rodar)\n",
        "\n",
        "                nome_do_video = video_da_vez[:-4]\n",
        "\n",
        "                return timestamps, nome_do_video,source_folder, pasta_pra_rodar\n",
        "            \n",
        "    nome_do_video=0\n",
        "    timestamps=0  \n",
        "    return timestamps, nome_do_video,source_folder, pasta_pra_rodar\n",
        "        \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BEwXvNrbOT6E"
      },
      "source": [
        "# Person tracking and fall detection\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XwBo-LT3OEIr"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "from person_tracking import tracking_frames\n",
        "from data_utils import *\n",
        "import argparse\n",
        "import config\n",
        "from trainer.fusiondiffroigan import Params,Fusion_Diff_ROI_3DCAE_GAN3D\n",
        "from models import diff_ROI_C3D_AE_no_pool\n",
        "\n",
        "\n",
        "from models import diff_ROI_C3D_AE_no_pool,ROI_C3D_AE_no_pool,Fusion_C3D_no_pool\n",
        "from trainer.fusiondiffroigan import Params,Fusion_Diff_ROI_3DCAE_GAN3D\n",
        "from trainer.util import agg_window,create_windowed_arr,get_output,gather_auc_avg_per_tol,join_mean_std,create_diff_mask\n",
        "\n",
        "import matplotlib.animation as animation\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "def gray_color_image(gray):\n",
        "    gray_scaled=np.expand_dims(cv2.normalize(gray,None,0,1,cv2.NORM_MINMAX),axis=-1)\n",
        "    gray_scaled=gray_scaled*255\n",
        "    gray_scaled=gray_scaled.astype(np.uint8)\n",
        "    org_color=np.concatenate([gray_scaled,gray_scaled,gray_scaled],axis=-1)\n",
        "    return org_color\n",
        "def roi_gray_color_image(roi_gray,box_fr):\n",
        "    height,width=roi_gray.shape[0],roi_gray.shape[1]\n",
        "    color_img=np.zeros((height,width,3),dtype='uint8')\n",
        "    left, top, right, bottom=int(box[1]*width),int(box[0]*height),int(box[3]*width),int(box[2]*height)\n",
        "    color_img[top:bottom,left:right,:]=gray_color_image(roi_gray[top:bottom,left:right,:])\n",
        "    return color_img\n",
        "    \n",
        "\n",
        "def get_cross_window_frames(recons_seq,height,width,channels,win_length):\n",
        "    '''\n",
        "        Take mean of the reconstructed frames present in different windows corresponding to the actual frame timestamp\n",
        "    '''\n",
        "    seq_num=recons_seq.shape[0]+win_length-1\n",
        "    sum_frames=np.zeros((seq_num,height,width,channels),dtype='float')\n",
        "    count_frames=np.zeros((seq_num))\n",
        "    for i in range(recons_seq.shape[0]):\n",
        "        sum_frames[i:i+win_length,:]+=recons_seq[i,:]\n",
        "        count_frames[i:i+win_length]+=1\n",
        "    return sum_frames/count_frames[:, np.newaxis, np.newaxis, np.newaxis]\n",
        "\n",
        "'''\n",
        "This function is the extension of function animate_fall_detect_Spresen() from https://github.com/JJN123/Fall-Detection/blob/master/util.py\n",
        "\n",
        "'''\n",
        "def animate_fall_detect_animation(actual_frames, recons,recons_timestamp, scores,score_type='RE_mean',threshold = 0,to_save = './test.mp4'):\n",
        "    '''\n",
        "    Create animation from actual frames, reconstructed frames and frame level anomaly score with timestamps\n",
        "    '''\n",
        "    import matplotlib.gridspec as gridspec\n",
        "    gs = gridspec.GridSpec(2,2,height_ratios = [2,1])\n",
        "    \n",
        "    ht, wd = 64,64\n",
        "\n",
        "    eps = .0001\n",
        "    #setup figure\n",
        "    #fig = plt.figure()\n",
        "    fig, ((ax1,ax3)) = plt.subplots(1,2,figsize = (6,6))\n",
        "\n",
        "    ax1.axis('off')\n",
        "    ax3.axis('off')\n",
        "    #ax1=fig.add_subplot(2,2,1)\n",
        "\n",
        "    ax1=fig.add_subplot(gs[0,0])\n",
        "    ax1.set_title(\"Original\")\n",
        "    ax1.set_xticks([])\n",
        "    ax1.set_yticks([])\n",
        "\n",
        "\n",
        "    #ax2=fig.add_subplot(gs[-1,0])\n",
        "    ax2=fig.add_subplot(gs[1,:])\n",
        "\n",
        "    #ax2.set_yticks([])\n",
        "    #ax2.set_xticks([])\n",
        "    ax2.set_ylabel('Score')\n",
        "    ax2.set_xlabel('Frame')\n",
        "    ax2.set_xlim([1, len(actual_frames)])\n",
        "    if threshold != 0:\n",
        "        ax2.axhline(y= threshold, color='r', linestyle='dashed', label = 'RRE')\n",
        "        ax2.legend()\n",
        "\n",
        "    #ax3=fig.add_subplot(2,2,2)\n",
        "    ax3=fig.add_subplot(gs[0,1])\n",
        "    ax3.set_title(\"Reconstruction\")\n",
        "    ax3.set_xticks([])\n",
        "    ax3.set_yticks([])\n",
        "\n",
        "    #dictionary to frame number to indices\n",
        "    indices=list(range(len(recons_timestamp)))\n",
        "    track_indices=dict(zip(recons_timestamp,indices))\n",
        "    #set up list of images for animation\n",
        "    ims=[]\n",
        "    track_ind=None\n",
        "    for time in tqdm(range(len(actual_frames))):\n",
        "        #plot images\n",
        "        im1 = ax1.imshow(actual_frames[time])\n",
        "        figure= recons[time]\n",
        "        im2 = ax3.imshow(figure, cmap = 'gray', aspect = 'equal')\n",
        "        \n",
        "        if time+1 in track_indices:\n",
        "            track_ind=track_indices[time+1]\n",
        "            \n",
        "        if track_ind is not None:\n",
        "            scores_curr = scores[:track_ind+1]\n",
        "            track_num=recons_timestamp[:track_ind+1]\n",
        "            \n",
        "            plot, = ax2.plot(track_num, scores_curr,'b.',linestyle='--', marker='.',label=score_type)\n",
        "        else:\n",
        "            plot, = ax2.plot([],'b.')\n",
        "#             plot_r, = ax2.plot([],'b.')\n",
        "            \n",
        "            \n",
        "    \n",
        "\n",
        "        ims.append([im1, plot, im2]) #list of ims\n",
        "\n",
        "    #run animation\n",
        "    ani = animation.ArtistAnimation(fig,ims, interval= 30, repeat=False)\n",
        "    \n",
        "    ani.save(to_save)\n",
        "\n",
        "    ani.event_source.stop()\n",
        "    del ani\n",
        "    plt.close()\n",
        "#     plt.show()\n",
        "\n",
        "\n",
        "def cvsc(animation_out=True):\n",
        "    ####Timer\n",
        "    inicio=time.time()\n",
        "    #user input\n",
        "    detection_threshold=0.3\n",
        "    folder_path='/home/monitora/Documents/Motion and Region A A L F D  T I/dataset/Thermal/frame/Fall/Fall37'\n",
        "    \n",
        "    #parameters\n",
        "    WIDTH,HEIGHT=config.WIDTH,config.HEIGHT#original data specs\n",
        "    win_length=config.WIN_LENGTH\n",
        "    LOAD_DATA_SHAPE=config.LOAD_DATA_SHAPE\n",
        "    width, height,channels = LOAD_DATA_SHAPE[0],LOAD_DATA_SHAPE[1],LOAD_DATA_SHAPE[2]\n",
        "    break_win=config.SPLIT_GAP\n",
        "    stride=config.STRIDE\n",
        "    \n",
        "    input_folder=folder_path\n",
        "    #reading and sorting image paths\n",
        "    frames_path = glob.glob(input_folder+'/*.jpg') + glob.glob(input_folder+'/*.png')\n",
        "    frames_path,numbers = sort_frames(frames_path,'Thermal')\n",
        "\n",
        "    #person tracking\n",
        "    boxes,track_numbers=tracking_frames(detection_threshold,frames_path,numbers,otsu_box=True)\n",
        "\n",
        "    ####Timer\n",
        "    fim=time.time()\n",
        "    ROI_M_time = fim - inicio\n",
        "    inicio=time.time()\n",
        "\n",
        "    # box_path='box.npy'\n",
        "    # numbers_path='numbers.npy'\n",
        "    # if os.path.exists(box_path) and  os.path.exists(numbers_path):\n",
        "    #     boxes=np.load(box_path)\n",
        "    #     track_numbers=np.load(numbers_path)\n",
        "    # else:\n",
        "    #     np.save(box_path,boxes)\n",
        "    #     np.save(numbers_path,track_numbers)\n",
        "    \n",
        "    #preprocess boxes- remove -ve coordinates\n",
        "    boxes_proc=np.array([improve_box_cord(box,WIDTH,HEIGHT,offset=10) for box in boxes])\n",
        "    #creating dictionary with key:frame_num value:box with coordinates are scaled in range 0 to 1\n",
        "    boxes_fr=boxes_proc.copy()\n",
        "    boxes_fr=boxes_fr.astype('float64')\n",
        "    boxes_fr[:,0]=boxes_fr[:,0]/(1.0*HEIGHT)\n",
        "    boxes_fr[:,2]=boxes_fr[:,2]/(1.0*HEIGHT)\n",
        "    boxes_fr[:,1]=boxes_fr[:,1]/(1.0*WIDTH)\n",
        "    boxes_fr[:,3]=boxes_fr[:,3]/(1.0*WIDTH)\n",
        "    num_box_dict=dict(zip(track_numbers,boxes_fr))\n",
        "\n",
        "    print(\"Thermal preprocessing....\")\n",
        "    video={}\n",
        "\n",
        "    #preprocessing all frames\n",
        "    video[\"ALL_FRAME\"],_,_=preprocess_frames(frames_path,numbers,process_list=['Processed'],ht=height,wd=width,channels=channels,ROI_array=None)\n",
        "    \n",
        "    tracked_frames_path=[]\n",
        "\n",
        "    for num in track_numbers:\n",
        "        tracked_frames_path.append(frames_path[num-1])\n",
        "    #preprocessing tracked frames\n",
        "    #Data as numpy array and list of sorted frame numbers\n",
        "    data,frame_numbers,frames_path=preprocess_frames(tracked_frames_path,track_numbers,process_list=['Processed','ROI_frame'],ht=height,wd=width,channels=channels,ROI_array=boxes_proc)\n",
        "    #creating sub vidoes\n",
        "    data_list,frame_numbers_list=split_data_tracks(data,frame_numbers,gap=break_win,win_length=win_length)\n",
        "    #Split frames path\n",
        "    frames_path_list,_=split_data_tracks(frames_path,frame_numbers,gap=break_win,win_length=win_length)\n",
        "    video['ROI_FRAME']=data_list\n",
        "    video['NUMBER']=frame_numbers_list\n",
        "    video['PATH']=frames_path_list\n",
        "    print(\"\\nCreating MASK data...........\\n\")\n",
        "    video['MASK']=create_ROI_mask(ROI_boxes=boxes_proc,ROI_numbers=track_numbers,img_shape=(config.HEIGHT,config.WIDTH,1),load_shape=config.LOAD_DATA_SHAPE,win_length=config.WIN_LENGTH,split_gap=config.SPLIT_GAP)\n",
        "    #optical flow computation\n",
        "\n",
        "    ####Timer\n",
        "    fim=time.time()\n",
        "    OFC_time = fim - inicio\n",
        "    inicio=time.time()\n",
        "\n",
        "    #image sample\n",
        "    sub_video_num=0\n",
        "    index=10\n",
        "    frame_num=video['NUMBER'][sub_video_num][index]\n",
        "    \n",
        "    org_frame=video[\"ALL_FRAME\"][frame_num-1]#1 numbering\n",
        "    roi_frame=video['ROI_FRAME'][sub_video_num][index]\n",
        "    mask=video['MASK'][sub_video_num][index]\n",
        "    box=num_box_dict[frame_num]\n",
        "    \n",
        "    left, top, right, bottom=int(box[1]*width),int(box[0]*height),int(box[3]*width),int(box[2]*height)\n",
        "    #plt.imshow(cv2.rectangle(gray_color_image(org_frame), (left, top), (right, bottom), (0, 0, 255),1))\n",
        "    #plt.imshow(mask[:,:,0],cmap='gray')\n",
        "    #plt.imshow(roi_gray_color_image(roi_frame,box))\n",
        "    \n",
        "    #parameters\n",
        "    dset = config.track_root_folder\n",
        "    d_type='ROI_Fusion'\n",
        "    thermal_channels=1\n",
        "    flow_channels=3\n",
        "    regularizer_list = ['BN']\n",
        "    epochs_trained=299\n",
        "    lambdas=[1.0,1.0,1.0]#T_S,T_T,F\n",
        "    thermal_3dcae_path='/home/monitora/Documents/Motion and Region A A L F D  T I/mrfd/Thermal_track/ROI_Fusion/ROI_C3DAE-no_pool-BN_diff_ROI_C3DAE_no_pool-BN_Fusion_C3D-no_pool-BN/lambda_TS1.0_TT1.0_F1.0/models/GAN_T_R_weights_epoch-299.h5'\n",
        "\n",
        "    param=Params(width=width, height=height,win_length=win_length,thermal_channels=thermal_channels,flow_channels=flow_channels \\\n",
        "             ,dset=dset,d_type=d_type,regularizer_list=regularizer_list,break_win=break_win)\n",
        "    param.thermal_lambda_S=lambdas[0]\n",
        "    param.thermal_lambda_T=lambdas[1]\n",
        "    param.flow_lambda=lambdas[2]\n",
        "\n",
        "    #trainer\n",
        "    GAN3D=Fusion_Diff_ROI_3DCAE_GAN3D(train_par=param,stride=stride)\n",
        "    #thermal reconstructor model \n",
        "    #initialization\n",
        "    TR, TR_name, _ = diff_ROI_C3D_AE_no_pool(img_width=param.width, img_height=param.height, win_length=param.win_length, regularizer_list=param.regularizer_list,channels=param.thermal_channels,lambda_S=param.thermal_lambda_S,lambda_T=param.thermal_lambda_T,d_type='thermal')\n",
        "\n",
        "    #Loading weights\n",
        "    if os.path.isfile(thermal_3dcae_path):\n",
        "        TR.load_weights(thermal_3dcae_path)\n",
        "        GAN3D.T_R=TR\n",
        "        print(\"Model weights loaded successfully........\")\n",
        "    else:\n",
        "        print(\"Saved model weights not found......\")\n",
        "        \n",
        "    ##### Sliding window\n",
        "    vid_thermal_list=video['ROI_FRAME']\n",
        "    vid_thermal_mask_list=video['MASK']\n",
        "    frame_numbers_cat=np.concatenate(video['NUMBER'])\n",
        "    \n",
        "    #creating windows of thermal frames for each subvideo separately\n",
        "    thermal_data_list = [vid.reshape(len(vid), param.width,param.height, param.thermal_channels) for vid in vid_thermal_list]\n",
        "    thermal_data_windowed_list = [create_windowed_arr(test_data, stride, param.win_length) for test_data in thermal_data_list]#create_windowe\n",
        "\n",
        "    # creating windows of mask data\n",
        "    thermal_mask_list = [vid.reshape(len(vid), param.width,param.height, param.thermal_channels) for vid in vid_thermal_mask_list]\n",
        "\n",
        "    thermal_mask_windowed_list = [create_windowed_arr(test_data, stride, param.win_length).astype('int8') for test_data in thermal_mask_list]\n",
        "    # creating windows of mask of difference frames\n",
        "    diff_mask_windowed_list=[create_diff_mask(mask_windows) for mask_windows in thermal_mask_windowed_list]\n",
        "    \n",
        "    num_sub_videos=len(thermal_data_windowed_list)\n",
        "    \n",
        "    #Model prediction, frame level anomaly scores and thermal reconstruction\n",
        "    \n",
        "    #frame based anomaly scores\n",
        "    x_std_RE=[]\n",
        "    x_mean_RE=[]\n",
        "    mean_frames=[]\n",
        "    for index in range(num_sub_videos):\n",
        "        test_data_masked_windowed=thermal_data_windowed_list[index]\n",
        "        test_mask_windowed=thermal_mask_windowed_list[index]\n",
        "        test_diff_mask_windowed=diff_mask_windowed_list[index]\n",
        "\n",
        "        RE_dict, recons_seq = GAN3D.get_T_S_RE_all_agg(thermal_data=test_data_masked_windowed,thermal_masks=test_mask_windowed,diff_masks=test_diff_mask_windowed) #Return dict with value for each score style\n",
        "        x_std_RE.append(RE_dict['x_std'])\n",
        "        x_mean_RE.append(RE_dict['x_mean'])\n",
        "        mean_recons_seq=get_cross_window_frames(recons_seq,param.height,param.width, param.thermal_channels,param.win_length)\n",
        "        mean_frames.append(mean_recons_seq)\n",
        "    \n",
        "\n",
        "    x_std_RE=np.concatenate(x_std_RE)\n",
        "    x_mean_RE=np.concatenate(x_mean_RE)\n",
        "    mean_frames=np.concatenate(mean_frames)\n",
        "    print(mean_frames.shape)\n",
        "    print(len(frame_numbers_cat))\n",
        "    \n",
        "    #try:\n",
        "    #    plt.imshow(mean_frames[50,:,:,0],cmap='gray')\n",
        "    #except:\n",
        "    #    pass\n",
        "    \n",
        "    \n",
        "    '''#para nao mais mostrar os graficos dos videos\n",
        "    #Anomaly score plot\n",
        "    plt.plot(frame_numbers_cat,x_std_RE, label='RE_std',linestyle='--', marker='.')\n",
        "    plt.plot(frame_numbers_cat,x_mean_RE, label='RE_mean',linestyle='--', marker='.')\n",
        "    # plt.xticks([i+1 for i in range(max(frame_numbers))])\n",
        "    plt.xlim(1,max(frame_numbers_cat))\n",
        "    # plt.ylim(0,1)\n",
        "    plt.legend()\n",
        "    # plt.axvspan(start,end, alpha = 0.5)\n",
        "    plt.show()\n",
        "    '''\n",
        "    ############  animation  #####################\n",
        "    #dictionary tracked frames number to index\n",
        "    indices=list(range(len(frame_numbers_cat)))\n",
        "    track_indices=dict(zip(frame_numbers_cat,indices))\n",
        "    \n",
        "    #convert gray to rgb, add boxes to track frames\n",
        "    actual_frames=video[\"ALL_FRAME\"]\n",
        "    org_color_images=[]\n",
        "    recon_color_images=[]\n",
        "    #lan\n",
        "    frame_num = []\n",
        "    lan_box = []\n",
        "    \n",
        "    \n",
        "    for i in range(len(actual_frames)):\n",
        "        frame_num.append(i+1)\n",
        "        if i+1 in track_indices:\n",
        "            box=num_box_dict[i+1]\n",
        "            left, top, right, bottom=int(box[1]*width),int(box[0]*height),int(box[3]*width),int(box[2]*height)\n",
        "            lan_box.append([left, top, right, bottom])\n",
        "            #add box in org frame\n",
        "            clr_img=cv2.rectangle(gray_color_image(actual_frames[i]), (left, top), (right, bottom), (0, 0, 255),1)\n",
        "            org_color_images.append(clr_img)\n",
        "            #recons image -> color img\n",
        "            recon_im=gray_color_image(mean_frames[track_indices[i+1]])\n",
        "            clr_img=cv2.rectangle(recon_im, (left, top), (right, bottom), (0, 0, 255),1)\n",
        "            recon_color_images.append(clr_img)\n",
        "        else:\n",
        "            lan_box.append([])\n",
        "            org_color_images.append(gray_color_image(actual_frames[i]))\n",
        "            recon_color_images.append(np.zeros((height,width,3),dtype='uint8'))\n",
        "            \n",
        "    print(len(org_color_images))\n",
        "    print(len(recon_color_images))\n",
        "    \n",
        "    #exemplo de um frame\n",
        "    #try:\n",
        "    #    index=500\n",
        "    #    plt.imshow(org_color_images[index])\n",
        "    #    plt.show()\n",
        "    #    plt.imshow(recon_color_images[index])\n",
        "    #    plt.show()\n",
        "    #except:\n",
        "    #    pass\n",
        "    \n",
        "    if animation_out:\n",
        "        demo_samples_path=folder_path\n",
        "        #os.makedirs(demo_samples_path,exist_ok=True)\n",
        "    \n",
        "        #user_input\n",
        "        score_type='mean'\n",
        "        video_name='animation'\n",
        "        save_path=demo_samples_path+'/'+video_name+'_'+score_type+'.mp4'\n",
        "    \n",
        "        animate_fall_detect_animation(org_color_images,recon_color_images,frame_numbers_cat, scores=x_mean_RE,score_type='RE_'+score_type,to_save = save_path)\n",
        "        \n",
        "    #new\n",
        "    scores=[]\n",
        "    falls=[]\n",
        "    \n",
        "    cont_list_menor=0\n",
        "    for num in frame_num:\n",
        "        if num in frame_numbers_cat:\n",
        "            scores.append(x_mean_RE[cont_list_menor])\n",
        "            cont_list_menor+=1\n",
        "        else:\n",
        "            scores.append(None)\n",
        "            \n",
        "    for score in scores:\n",
        "        try:\n",
        "            if score >= 0.012:\n",
        "                fall=1\n",
        "            else:\n",
        "                fall=0\n",
        "        except:\n",
        "            #None: sem score\n",
        "            fall=0\n",
        "        falls.append(fall)\n",
        "    \n",
        "    print(\"LISTAS\"\n",
        "          +\"\\n falls: \"+str(len(falls))\n",
        "         +\" frame_num: \"+str(len(frame_num))\n",
        "         +\" lan_box: \"+str(len(lan_box))\n",
        "         +\" scores: \"+str(len(scores)))\n",
        "    #print(falls)\n",
        "    #print(frame_num)\n",
        "    #print(lan_box)\n",
        "    #print(scores)\n",
        "\n",
        "    ####Timer\n",
        "    fim=time.time()\n",
        "    GAN_time = fim - inicio\n",
        "    timers_CVSC=[ROI_M_time,OFC_time,GAN_time]\n",
        "\n",
        "    return falls,frame_num,lan_box,scores,timers_CVSC\n",
        "\n",
        "    \n",
        "\n",
        "    \n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "BEwXvNrbOT6E",
        "l2XxmHS-OEI9",
        "4hqzGeCyPmcx",
        "PDBroStSWDWr",
        "Sp-obILUWDWt",
        "MzQIKhmpWDWv",
        "AfJl2hmqWDWz",
        "POqAQWUtWDW6",
        "RdftM0uxWDW9",
        "Grq2jtK3WDW9",
        "RLXZMWRLWDXA",
        "AbqBuuIsWDXG",
        "xj8FqyhnWDXI",
        "v3xe8k-2WDXI",
        "e4wHPASDWDXI",
        "7K-l-l-FWDXO",
        "HU1Z9TZwWDXS",
        "MmRq1LgmWDXV",
        "I9TNYMcTWDXV",
        "YPjmiE3AWDXW",
        "33SpZmhSWDXa",
        "E8qzslBOP9uT",
        "XMHlxz37P9uU",
        "1n3Q2hUPP9uU",
        "IEuriejJAtio",
        "9XPD55VPP9uX",
        "ScEzTvIk-uBO",
        "4Z9zFpLb-zBP",
        "5gS8I5giP9ub",
        "2hH3NeXmP9ud",
        "M4utW_84P9ud",
        "0M414my-K2gX",
        "lCVdI8tsP9ue",
        "98mpid_HP9uh",
        "Hrdyzbs30rcw",
        "iTHBZtap0rcx",
        "mG1DPrYi0rcx",
        "n3ridJW0G0jS",
        "CPO0XEWC0rc3",
        "Q1o_rVaX0rc6",
        "FSXOIP1Y0rc8",
        "LN5DGRr70rc-",
        "quuzNzw-0rc_",
        "d5LOImg10rdA",
        "ByjiEa2P0rdB",
        "Kf4yNB120rdF",
        "oI6kSCfc0rdJ",
        "CAqRcEQ2YPTc",
        "en5k8-RTYPTe",
        "H7rUUjVHYPTf",
        "hvOwbSG8YPTk",
        "-PYbIBgFYPTr",
        "Xt5x4lx6YPTw",
        "KhkaUG4cYPTy",
        "husIc9CSYPT2",
        "7S5lr2kaYPT7",
        "RBPGAETAYPT7",
        "-wTchCvbYPUB",
        "XbD98JGQYPUG",
        "d70MdKpuYPUO",
        "0lqZ9-tqpgrh",
        "ThVd0PkEpgsw",
        "bs5QNBiZpgsx",
        "m6MJhs-Xpgsx",
        "DYCfKuctpgsy",
        "4HNzFjnjpgsz",
        "j4eGpDtlpgs1",
        "d4Mv354Npgs2",
        "Wfj265K6GKrM",
        "RN0Wi6LYpgs4",
        "hg0BuMtSpgs4",
        "ZVKeA_iPpgs6",
        "2YOhA9M8pgs8",
        "u2qHM7MBNPvH",
        "B-LgqGevczVD",
        "YNELSn1dc517",
        "Sa6byRd7dKOr",
        "D1GOXSVVqKFE",
        "dD06AusOyFVP",
        "geopcnFYpDz2",
        "agEfYljTd3yS",
        "lQtdP_0XMB5c",
        "Iipg_lSmSpKo",
        "D99tQSo_TEEG",
        "qooiQeTfZYKW",
        "TXEAXF150eF3",
        "slswqc1gewx1",
        "KUUxpy0GT-Nh",
        "r9z3ChAsanck",
        "wQd4tURIakZr",
        "ZlddkFEfnvhw",
        "f3F7mlSxfD4a",
        "UnqXK-Uyk1yH",
        "6mugejx5Kv0P",
        "SF50LfnCxGk0",
        "E4qTxCTeNHdL",
        "qZbH_2GX293F",
        "4nGqDlDLOEGf",
        "wQVOVT6l2YgM",
        "owUVHPsGXfuj",
        "x9Szp4lAR10L",
        "dB0qnR6pk43K",
        "kl_3OBkBRr6X",
        "gtSDHOBMrIGX",
        "fEnD9OMlCc9o",
        "AJbxvagYYkG-",
        "d9AzeRwfSgHq",
        "Qj99mK7Xjm6z",
        "pFP4B-eE1qzv",
        "JGjRHHBBX0Dd",
        "apQNPkeDN9KW",
        "Mh6tGlCJN9KX",
        "J_m35N77N9Ka",
        "8mGVKe4uab8Y",
        "sC4Orx7EaqaU",
        "n1ClIVfdelta"
      ],
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}